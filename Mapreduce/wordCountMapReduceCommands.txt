[root@sandbox-hdp mapReduce]# ls -lrt
total 12
-rw-r--r-- 1 root root 594 Sep 16 19:48 mapper.py
-rw-r--r-- 1 root root 962 Sep 16 19:48 reducer.py
-rw-r--r-- 1 root root 299 Sep 16 20:24 wordCountData.txt
[root@sandbox-hdp mapReduce]#
[root@sandbox-hdp mapReduce]#
[root@sandbox-hdp mapReduce]# hdfs dfs -put wordCountData.txt /user/root/
[root@sandbox-hdp mapReduce]#
[root@sandbox-hdp mapReduce]# hdfs dfs -ls /user/root/
Found 3 items
drwx------   - root hdfs          0 2021-09-16 20:18 /user/root/.Trash
drwx------   - root hdfs          0 2021-09-16 20:01 /user/root/.staging
-rw-r--r--   1 root hdfs        299 2021-09-16 20:25 /user/root/wordCountData.txt
[root@sandbox-hdp mapReduce]# pwd
/root/mapReduce
[root@sandbox-hdp mapReduce]# hadoop jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming-3.1.1.3.0.1.0-187.jar \
> -input /user/root/wordCountData.txt \
> -output /user/root/wordCountDataOutput \
> -mapper mapper.py \
> -reducer reducer.py \
> -file /root/mapReduce/mapper.py \
> -file /root/mapReduce/reducer.py
21/09/16 20:29:54 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/root/mapReduce/mapper.py, /root/mapReduce/reducer.py] [/usr/hdp/3.0.1.0-187/hadoop-mapreduce/hadoop-streaming-3.1.1.3.0.1.0-187.jar] /tmp/streamjob1447688368843745158.jar tmpDir=null
21/09/16 20:29:56 INFO client.RMProxy: Connecting to ResourceManager at sandbox-hdp.hortonworks.com/172.18.0.2:8050
21/09/16 20:29:56 INFO client.AHSProxy: Connecting to Application History server at sandbox-hdp.hortonworks.com/172.18.0.2:10200
21/09/16 20:29:56 INFO client.RMProxy: Connecting to ResourceManager at sandbox-hdp.hortonworks.com/172.18.0.2:8050
21/09/16 20:29:56 INFO client.AHSProxy: Connecting to Application History server at sandbox-hdp.hortonworks.com/172.18.0.2:10200
21/09/16 20:29:57 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/root/.staging/job_1631799447719_0007
21/09/16 20:29:59 INFO mapred.FileInputFormat: Total input files to process : 1
21/09/16 20:29:59 INFO mapreduce.JobSubmitter: number of splits:2
21/09/16 20:30:00 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1631799447719_0007
21/09/16 20:30:00 INFO mapreduce.JobSubmitter: Executing with tokens: []
21/09/16 20:30:00 INFO conf.Configuration: found resource resource-types.xml at file:/etc/hadoop/3.0.1.0-187/0/resource-types.xml
21/09/16 20:30:01 INFO impl.YarnClientImpl: Submitted application application_1631799447719_0007
21/09/16 20:30:01 INFO mapreduce.Job: The url to track the job: http://sandbox-hdp.hortonworks.com:8088/proxy/application_1631799447719_0007/
21/09/16 20:30:01 INFO mapreduce.Job: Running job: job_1631799447719_0007
21/09/16 20:30:13 INFO mapreduce.Job: Job job_1631799447719_0007 running in uber mode : false
21/09/16 20:30:13 INFO mapreduce.Job:  map 0% reduce 0%
21/09/16 20:30:37 INFO mapreduce.Job:  map 33% reduce 0%
21/09/16 20:30:38 INFO mapreduce.Job:  map 50% reduce 0%
21/09/16 20:30:42 INFO mapreduce.Job:  map 100% reduce 0%
21/09/16 20:30:52 INFO mapreduce.Job:  map 100% reduce 100%
21/09/16 20:30:52 INFO mapreduce.Job: Job job_1631799447719_0007 completed successfully
21/09/16 20:30:52 INFO mapreduce.Job: Counters: 53
        File System Counters
                FILE: Number of bytes read=497
                FILE: Number of bytes written=715803
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=687
                HDFS: Number of bytes written=297
                HDFS: Number of read operations=11
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
        Job Counters
                Launched map tasks=2
                Launched reduce tasks=1
                Data-local map tasks=2
                Total time spent by all maps in occupied slots (ms)=196704
                Total time spent by all reduces in occupied slots (ms)=40668
                Total time spent by all map tasks (ms)=49176
                Total time spent by all reduce tasks (ms)=10167
                Total vcore-milliseconds taken by all map tasks=49176
                Total vcore-milliseconds taken by all reduce tasks=10167
                Total megabyte-milliseconds taken by all map tasks=50356224
                Total megabyte-milliseconds taken by all reduce tasks=10411008
        Map-Reduce Framework
                Map input records=1
                Map output records=48
                Map output bytes=395
                Map output materialized bytes=503
                Input split bytes=238
                Combine input records=0
                Combine output records=0
                Reduce input groups=33
                Reduce shuffle bytes=503
                Reduce input records=48
                Reduce output records=33
                Spilled Records=96
                Shuffled Maps =2
                Failed Shuffles=0
                Merged Map outputs=2
                GC time elapsed (ms)=606
                CPU time spent (ms)=6680
                Physical memory (bytes) snapshot=1704861696
                Virtual memory (bytes) snapshot=8326172672
                Total committed heap usage (bytes)=1576009728
                Peak Map Physical memory (bytes)=750637056
                Peak Map Virtual memory (bytes)=2841178112
                Peak Reduce Physical memory (bytes)=205369344
                Peak Reduce Virtual memory (bytes)=2648465408
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=449
        File Output Format Counters
                Bytes Written=297
21/09/16 20:30:52 INFO streaming.StreamJob: Output directory: /user/root/wordCountDataOutput
[root@sandbox-hdp mapReduce]#
[root@sandbox-hdp mapReduce]#
[root@sandbox-hdp mapReduce]#
[root@sandbox-hdp mapReduce]# hdfs dfs -ls /user/root/
Found 4 items
drwx------   - root hdfs          0 2021-09-16 20:18 /user/root/.Trash
drwx------   - root hdfs          0 2021-09-16 20:30 /user/root/.staging
-rw-r--r--   1 root hdfs        299 2021-09-16 20:25 /user/root/wordCountData.txt
drwxr-xr-x   - root hdfs          0 2021-09-16 20:30 /user/root/wordCountDataOutput
[root@sandbox-hdp mapReduce]# hdfs dfs -ls /user/root/wordCountDataOutput/
Found 2 items
-rw-r--r--   1 root hdfs          0 2021-09-16 20:30 /user/root/wordCountDataOutput/_SUCCESS
-rw-r--r--   1 root hdfs        297 2021-09-16 20:30 /user/root/wordCountDataOutput/part-00000
[root@sandbox-hdp mapReduce]# hdfs dfs -cat /user/root/wordCountDataOutput/part-00000
Apache  1
As      2
Hadoop  2
MapReduce       3
a       2
across  1
after   1
always  1
cluster.        1
component,      1
enables 1
heart   1
hundreds        1
implies,        1
in      1
is      3
job     2
map     1
massive 1
name    1
of      3
or      1
paradigm        1
performed       1
processing      1
programming     1
reduce  1
scalability     1
sequence        1
servers 1
that    1
the     6
thousands       1
[root@sandbox-hdp mapReduce]#
[root@sandbox-hdp mapReduce]#
[root@sandbox-hdp mapReduce]#
